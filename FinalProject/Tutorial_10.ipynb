{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8SiEGX180kR"
      },
      "source": [
        "# Tutorial 10\n",
        "\n",
        "### Today's Topic:\n",
        "* Batch Normalization\n",
        "* Residual Neural Network\n",
        "* Pytorch utilizing GPU speedup \n",
        "* Torchani aev computer\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxtZeBnr80kW"
      },
      "source": [
        "## Batch Normalization\n",
        "Batch normalization (also known as batch norm) is a method used to make artificial neural networks faster and more stable through normalization of the layers' inputs by re-centering and re-scalin\n",
        "Documentation: https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html <br>\n",
        "expected input of size (N, C, H, W) <br>\n",
        "the Batch Normalization is done over the C dimension, computing statistics on (N, H, W) slices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6sy5KiN80kX",
        "outputId": "bc4d6d42-4b63-4d92-e91c-c6fa928c193b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20, 100, 35, 45])"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "inp = torch.randn(20, 100, 35, 45)\n",
        "bn = nn.BatchNorm2d(100)\n",
        "output = bn(inp)\n",
        "output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "X-oXj-_n80kY"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv = nn.ModuleList([nn.Conv2d(1,6,kernel_size=3,padding=1), #before pooling (B,6,32,32)\n",
        "                                  nn.Conv2d(6,24,kernel_size=3,padding=1), # (B,24,16,16)\n",
        "                                  nn.Conv2d(24,12,kernel_size=5)]) # (B,12,4,4)\n",
        "        self.pooling = nn.MaxPool2d(kernel_size=2)\n",
        "        self.fc = nn.ModuleList([nn.Linear(192,192),nn.Linear(192,10)])\n",
        "        self.activation = nn.ReLU()\n",
        "        self.bn = [nn.BatchNorm2d(6), nn.BatchNorm2d(24), nn.BatchNorm2d(12)]\n",
        "        \n",
        "    def forward(self, x):\n",
        "        for i in range(2):\n",
        "            x = self.pooling(self.activation(self.bn[i](self.conv[i](x))))\n",
        "        x = nn.Flatten()(self.activation(self.bn[-1](self.conv[2](x))))\n",
        "        x = self.activation(self.fc[0](x))\n",
        "        x = nn.Softmax(dim=-1)(self.fc[1](x))\n",
        "        return x\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3hvzyMK80kZ",
        "outputId": "174cee79-549d-4860-ace9-924a3070baba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  (conv): ModuleList(\n",
            "    (0): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): Conv2d(6, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (2): Conv2d(24, 12, kernel_size=(5, 5), stride=(1, 1))\n",
            "  )\n",
            "  (pooling): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc): ModuleList(\n",
            "    (0): Linear(in_features=192, out_features=192, bias=True)\n",
            "    (1): Linear(in_features=192, out_features=10, bias=True)\n",
            "  )\n",
            "  (activation): ReLU()\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "cnn = CNN()\n",
        "print(cnn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFrFwMT780ka",
        "outputId": "0c17aa9a-8583-436a-a36f-76d76f004e4c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "cnn(torch.randn(20, 1, 32, 32)).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcWSnh5I80ka"
      },
      "source": [
        "## Residual Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e7yYOaN80kb"
      },
      "source": [
        "### Additive vs concatenative skip connections\n",
        "\n",
        "![](Additive-skip-connections-vs-concatenative-skip-connections-Rectangles-represent-data.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "qPmQqocP80kb"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv = nn.ModuleList([nn.Conv2d(1,6,kernel_size=3,padding=1), #before pooling (B,6,32,32)\n",
        "                                  nn.Conv2d(6,24,kernel_size=3,padding=1), # (B,24,16,16)\n",
        "                                  nn.Conv2d(24,12,kernel_size=5)]) # (B,12,4,4)\n",
        "        self.pooling = nn.MaxPool2d(kernel_size=2)\n",
        "        self.fc = nn.ModuleList([nn.Linear(192,192),nn.Linear(192,10)])\n",
        "        self.activation = nn.ReLU()\n",
        "        self.bn = [nn.BatchNorm2d(6), nn.BatchNorm2d(24), nn.BatchNorm2d(12)]\n",
        "        \n",
        "    def forward(self, inp):\n",
        "        residual = inp\n",
        "        x = self.bn[0](self.conv[0](inp))\n",
        "        x = x + residual\n",
        "        x = self.pooling(self.activation(x))\n",
        "        x = self.pooling(self.activation(self.bn[1](self.conv[1](x))))\n",
        "        x = nn.Flatten()(self.activation(self.bn[2](self.conv[2](x))))\n",
        "        residual = x\n",
        "        y = self.fc[0](x)\n",
        "        y = y + residual\n",
        "        y = self.activation(y)\n",
        "        y = nn.Softmax(dim = -1)(self.fc[1](y))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1D1wIYRF80kb",
        "outputId": "3b41d0b7-57bf-41d7-bd52-d42217fe64e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  (conv): ModuleList(\n",
            "    (0): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): Conv2d(6, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (2): Conv2d(24, 12, kernel_size=(5, 5), stride=(1, 1))\n",
            "  )\n",
            "  (pooling): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc): ModuleList(\n",
            "    (0): Linear(in_features=192, out_features=192, bias=True)\n",
            "    (1): Linear(in_features=192, out_features=10, bias=True)\n",
            "  )\n",
            "  (activation): ReLU()\n",
            ")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20, 192])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "net = CNN()\n",
        "print(net)\n",
        "net(torch.randn(20, 1, 32, 32)).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYSKvL0d80kc"
      },
      "source": [
        "## MGCF cluster resources\n",
        "https://docs.google.com/document/d/1lIkJ6g772Ss5e-4CJ_xGjlVRfOVUq6gYnyGiEhtBc-Q/edit?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWu9QqJz80kc"
      },
      "source": [
        "## using GPU resources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jTiJa6O80kc"
      },
      "source": [
        "### checking available resources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leZrFOP480kd",
        "outputId": "3ef63db0-4e24-4287-9860-40fb15099d19"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXedYDlh80kd"
      },
      "source": [
        "To get the number of GPUs available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItvVLuG680kd",
        "outputId": "3c01440e-8005-4c93-ddf6-e850bb0352ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "torch.cuda.device_count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "veEPGyZJ80kd"
      },
      "outputs": [],
      "source": [
        "#torch.cuda.get_device_name(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fm7hYPnA80ke"
      },
      "source": [
        "### Move tensors to gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0szWV0f80ke"
      },
      "source": [
        "By default, the tensors are generated on the CPU. Even the model is initialized on the CPU. Thus one has to manually ensure that the operations are done using GPU. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18aFydYo80ke",
        "outputId": "e34d4f8d-ce3b-4233-99ad-d8ff7c4d5937"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "X_train = torch.FloatTensor([0., 1., 2.])\n",
        "X_train.is_cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXaJrDre80kf",
        "outputId": "5e5fa264-f01a-4ab0-f720-47043fef0a08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "X_train.get_device()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzWqAp0C80kf"
      },
      "source": [
        "It's a common PyTorch practice to initialize a variable, usually named device that will hold the device we’re training on (CPU or GPU). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vrVQA7s80kf",
        "outputId": "7d8ac7c1-c988-4bc3-a0c0-4e8feaf7019f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7l8P-So80kg",
        "outputId": "42a4ca1b-f14a-4733-c56b-cb09b2ecb7cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "X_train = X_train.to(device)\n",
        "X_train.is_cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a46Ua-VZ80kg",
        "outputId": "ab9909f1-d5f0-49bb-b554-c438a3b6a1f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "X_train.get_device()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MK3FYF7p80kh"
      },
      "source": [
        "The same logic applies to the model. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iB4otst_80kh",
        "outputId": "822d6d5a-d792-44f7-930c-08b78073705c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv): ModuleList(\n",
              "    (0): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): Conv2d(6, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (2): Conv2d(24, 12, kernel_size=(5, 5), stride=(1, 1))\n",
              "  )\n",
              "  (pooling): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc): ModuleList(\n",
              "    (0): Linear(in_features=192, out_features=192, bias=True)\n",
              "    (1): Linear(in_features=192, out_features=10, bias=True)\n",
              "  )\n",
              "  (activation): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "model = CNN()\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rW3CBVPg80kh"
      },
      "source": [
        "### Move tensors back to CPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dh40z43_80ki",
        "outputId": "af88e336-d87d-455c-c95b-b8a334b7ea41"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "X = torch.FloatTensor([0., 1., 2.])\n",
        "Y = torch.FloatTensor([0., 1., 2.])\n",
        "X_train = X_train.cpu()\n",
        "X_train.get_device()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YY3MKqwk80ki",
        "outputId": "95bf159a-9bf5-40b5-fa8a-1d3fcc2a757d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 2., 4.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "X+Y\n",
        "(X + Y).cpu().numpy()\n",
        "#cannot add tensors on separate devices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xy-0C5By80ki"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4J85zHo80kj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RX-LLhXV80kj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RRv7lN380kk"
      },
      "source": [
        "### AEV Computer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "WOHyxTpg80kk"
      },
      "outputs": [],
      "source": [
        "import torchani \n",
        "import torch\n",
        "import numpy as np\n",
        "from pyanitools import anidataloader\n",
        "# data = anidataloader(\"../../ANI1_dataset/ANI-1_release/ani_gdb_s07.h5\")\n",
        "data = anidataloader(\"ani_gdb_s05.h5\")\n",
        "data_iter = data.__iter__()\n",
        "mols = next(data_iter)\n",
        "# Extract the data\n",
        "P = mols['path']\n",
        "X = mols['coordinates']\n",
        "E = mols['energies']\n",
        "S = mols['species']\n",
        "sm = mols['smiles']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "gKriw5u080kl"
      },
      "outputs": [],
      "source": [
        "Rcr = 5.2\n",
        "EtaR = torch.tensor([16], dtype=torch.float)\n",
        "ShfR = torch.tensor([0.900000,1.168750,1.437500,1.706250,1.975000,2.243750,2.51250,2.781250,3.050000,3.318750,3.587500,3.856250,4.125000,4.39375,4.662500,4.931250])\n",
        "Rca = 3.5\n",
        "EtaA = torch.tensor([8], dtype=torch.float)\n",
        "ShfA = torch.tensor([0.900000,1.550000,2.200000,2.850000], dtype=torch.float)\n",
        "ShfZ = torch.tensor([0.19634954,0.58904862,0.9817477,1.3744468,1.7671459,2.1598449,2.552544,2.945243]) \n",
        "Zeta = torch.tensor([32], dtype=torch.float)\n",
        "species_order = ['H', 'C', 'N', 'O']\n",
        "num_species = len(species_order)\n",
        "\n",
        "aev_computer = torchani.AEVComputer(Rcr, Rca, EtaR, ShfR, EtaA, ShfA, ShfZ, Zeta, num_species)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mapping = {\"H\": 0, \"C\" : 1, \"N\": 2, \"O\": 3}\n",
        "species = np.array([mapping[atom] for atom in S])\n",
        "species = np.tile(species, (X.shape[0], 1))\n",
        "species = torch.tensor(species)\n",
        "X = torch.tensor(X)"
      ],
      "metadata": {
        "id": "3C6e6YWOHoJV"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Wo6uNKC80km",
        "outputId": "f238e5ec-1972-4cef-a453-0ac5e55a9c71"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10080, 16, 384])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "aev_output = aev_computer((species, X)) #SPecies: (Number, Atoms) A in [0, 1, 2, 3] Coords: (N, A, 3) Output : (N, A, 384)\n",
        "aev_output[1].shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Si7NrpYfHnjw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}