{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline \n",
    "\n",
    "* sklearn \n",
    "    * StandardScaler\n",
    "    * Train-test split and K-fold cross validation\n",
    "    * One-hot Encoder\n",
    "    * Multivariate linear regression\n",
    "* Q&A on HW3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize your dataset using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv(\"../../Datasets/wines.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In HW2, we normalize our data by our own code. This is how I did it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data\n",
    "feats=df.drop(['Start assignment','ranking'],axis=1)\n",
    "rankings=df['ranking']\n",
    "avg=np.average(feats,axis=0)\n",
    "std=np.std(feats,axis=0)\n",
    "feats=feats-avg\n",
    "feats=feats/std\n",
    "feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we can also do it through the sklearn package using [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "x=data.drop([\"Start assignment\",\"ranking\"],axis=1).values\n",
    "y=data['ranking'].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split and K-fold cross validation\n",
    "Documentation for [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)<br>\n",
    "Split our dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection as skl_model\n",
    "train_feat,test_feat,train_ranking,test_ranking=..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{len(train_ranking)} wines for training and {len(test_ranking)} for testing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation on [KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Framework for doing K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kfold(k,Xs,ys):\n",
    "    # The total number of examples for training the network\n",
    "    total_num=len(Xs)\n",
    "    # Built in K-fold function in Sci-Kit Learn\n",
    "    kf=skl_model.KFold(n_splits=k,shuffle=True)\n",
    "    \n",
    "    # kf.split: Generate indices to split data into training and test set.\n",
    "    for train_selector,test_selector in kf.split(range(total_num)):\n",
    "        # Decite training examples and testing examples for this fold\n",
    "        train_Xs=Xs[train_selector]\n",
    "        test_Xs=Xs[test_selector]\n",
    "        train_ys=ys[train_selector]\n",
    "        test_ys=ys[test_selector]\n",
    "        \n",
    "        val_array=[]\n",
    "        # Split training examples further into training and validation\n",
    "        train_in,val_in,train_real,val_real=skl_model.train_test_split(train_Xs,train_ys)\n",
    "        \n",
    "        # Fit the data to your model\n",
    "        # Train the model on your data\n",
    "        ...\n",
    "        for _ in range(max_epoch):\n",
    "            # Train model on a number of epochs, and test performance in the validation set\n",
    "            ...\n",
    "\n",
    "\n",
    "        # Report result for the fold with minimum error in validation set\n",
    "        train_error=model.evaluate(train_Xs,train_ys)\n",
    "        test_error=model.evaluate(test_Xs,test_ys)\n",
    "        print(\"Train error:\",train_error)\n",
    "        print(\"Test error:\",test_error)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L. Prechelt, \"Early Stopping -- but when?\", Neural Networks: Tricks of the trade. Springer, Berlin, Heidelberg, 1998. 55-69.\n",
    "[Link](https://link.springer.com/content/pdf/10.1007%2F978-3-642-35289-8_5.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pretend for a  minute that in our wine dataset ranks and start assignments are not labels but 2 categorical features, and we want to use one-hot encoders to describe them "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the features into categorical features and continuous features, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "categorical_feats=df[['Start assignment','ranking']]\n",
    "continuous_feats=x_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use [one-hot encoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) to transform the categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you can stack categorical and continuous features together for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can use one-hot encoders to encode the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_encoder=OneHotEncoder()\n",
    "y = np.array(df['ranking']).reshape(-1,1)\n",
    "output_encoder.fit(y)\n",
    "print(output_encoder.transform(y).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can decode the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate linear regression\n",
    "\n",
    "Let's try regression of function\n",
    "$$f(x,y)=3x+2y-5$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_X(number):\n",
    "    xs=(np.random.random(number)*2-1)*10\n",
    "    ys=(np.random.random(number)*2-1)*10\n",
    "    return np.hstack([xs.reshape(-1,1),ys.reshape(-1,1)])\n",
    "    \n",
    "def generate_data(number,stochascity=0.05):\n",
    "    X=generate_X(number)\n",
    "    xs=X[:,0]\n",
    "    ys=X[:,1]\n",
    "    fs=3*xs+2*ys-5\n",
    "    stochastic_ratio=(np.random.random(number)*2-1)*stochascity+1\n",
    "    return X,fs*stochastic_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "x,y=generate_data(5000,0.1)\n",
    "fig=plt.figure()\n",
    "ax=fig.gca(projection='3d')\n",
    "ax.scatter(x[:,0],x[:,1],y,s=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "X,y=generate_data(1000)\n",
    "reg=...\n",
    "print(reg.score(X,y))\n",
    "print(reg.coef_,reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=generate_X(5000)\n",
    "y=...\n",
    "fig=plt.figure()\n",
    "ax=fig.gca(projection='3d')\n",
    "ax.scatter(X[:,0],X[:,1],y,s=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
