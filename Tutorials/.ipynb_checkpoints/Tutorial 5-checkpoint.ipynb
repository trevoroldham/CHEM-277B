{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 5\n",
    "## Outline\n",
    "* Auto-differentiation frameworks: tensorflow and pytorch\n",
    "* Nomenclatures and general components of training a NN\n",
    "* PyTorch Tensors\n",
    "* Building an NN with pytorch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tenserflow vs PyTorch\n",
    "\n",
    "* PyTorch is developed by Facebook\n",
    "* TensorFlow is developed by Google. Keras is a front-end API of TensorFlow.\n",
    "\n",
    "### Similarities\n",
    "* Both are auto-differentiation framework\n",
    "* Both are open source\n",
    "* Both support CPU and GPU executions\n",
    "* Both have a large and active community\n",
    "\n",
    "### Dissimilarities\n",
    "#### Graph structure\n",
    "* Depending on version, TensorFlow is either static graph (version 1) or dynamic graph (version 2, with eager execution), but not as efficient as static graph\n",
    "* PyTorch is completely dynamic graph, and is efficient (sometimes even more efficient than TF with static graph!)\n",
    "\n",
    "\n",
    "#### Language support\n",
    "* TensorFlow supports a large variety of languages, i.e. C++, JavaScript, Python, C#, Ruby, and Swift.\n",
    "* PyTorch only supports python\n",
    "\n",
    "#### Deployment\n",
    "* Tensorflow can be easily deployed into different platforms, including mobile devices!\n",
    "* PyTorch code has to be converted into a different framework for depolyment\n",
    "\n",
    "### General suggestions\n",
    "* TensorFlow (with Keras) is easier to use for trying out existing models on a new dataset with minimal modifications on the architecture\n",
    "* It is also good for building simple models, like MLP networks \n",
    "* PyTorch is more useful in research, when you would like to try complicated NN architectures and needs to do a lot of debuggingg and validation of ideas, but do not care about deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nomenclatures and general components of training a NN\n",
    "* **Epoch**: Going through training data once\n",
    "* **Batch**: Set of data for calculating each gradient update\n",
    "* **Batch size**: Size of data in a batch\n",
    "* **Iteration**: One iteration = one gradient update\n",
    "* **Learning rate**: Coefficient multiplied to the gradient in each update\n",
    "\n",
    "### Neural network architecture\n",
    "* Multiple layer perceptron (MLP)\n",
    "* Convolutional neural network (CNN)\n",
    "* Graph convolutional neural network (GCN)\n",
    "* Recurrent neural network (RNN)\n",
    "* AutoEncoder (AE) \n",
    "* Attention mechanism / Transformer \n",
    "* ...\n",
    "\n",
    "### Optimizer\n",
    "* SGD (SGDM)\n",
    "* Adam\n",
    "* RMSProp\n",
    "* ...\n",
    "\n",
    "### Loss function\n",
    "* Mean squared error (MSE)\n",
    "* Mean absolute error (MAE)\n",
    "* Cosine similarity \n",
    "* Binary crossentropy (CE) \n",
    "* Categorical crossentropy\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch: Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we introduce the most fundamental PyTorch concept: the **Tensor**. A PyTorch Tensor is conceptually identical to a numpy array: a Tensor is an n-dimensional array, and PyTorch provides many functions for operating on these Tensors. Behind the scenes, Tensors can keep track of a computational graph and gradients, but theyâ€™re also useful as a generic tool for scientific computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "a = torch.tensor([[0.1, 1.2], [2.2, 3.1], [4.9, 5.2]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert numpy array to torch and vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.ones((3,2))\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the device and data types for torch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building NN for regression task\n",
    "For example, let's use a two hidden-layer MLP network [20, 15, 1] to simulate the Rosenbrock banana function!<br>\n",
    "$f(x,y)=(1-x)^2+10(y-x^2)^2$<br>\n",
    "$x\\in[-2,2],y\\in[-2,2]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib notebook\n",
    "\n",
    "def generate_X(number):\n",
    "    xs=(np.random.random(number)*2-1)*2\n",
    "    ys=(np.random.random(number)*2-1)*2\n",
    "    return np.hstack([xs.reshape(-1,1),ys.reshape(-1,1)])\n",
    "    \n",
    "def generate_data(number,stochascity=0.05):\n",
    "    X=generate_X(number)\n",
    "    xs=X[:,0]\n",
    "    ys=X[:,1]\n",
    "    fs=(1-xs)**2+10*(ys-xs**2)**2\n",
    "    stochastic_ratio=(np.random.random(number)*2-1)*stochascity+1\n",
    "    return np.hstack([xs.reshape(-1,1),ys.reshape(-1,1)]),fs*stochastic_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x, y = generate_data(5000, 0.3)\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.scatter(x[:, 0], x[:, 1], y, s=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a PyTorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_func = ...\n",
    "optimizer = ...\n",
    "\n",
    "for i in range(100):\n",
    "    train_X, train_y = generate_data(128, stochascity=0.1)\n",
    "    train_X = torch.tensor(train_X, dtype=torch.float)\n",
    "    train_y = torch.tensor(train_y, dtype=torch.float)\n",
    "    ...\n",
    "    print(\"Iteration %d: Loss value - %.4f\" % (i + 1, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "new_X = generate_X(5000)\n",
    "...\n",
    "fig = plt.figure()\n",
    "ax=fig.gca(projection='3d')\n",
    "ax.scatter(new_X[:, 0], new_X[:, 1], new_y, s=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
