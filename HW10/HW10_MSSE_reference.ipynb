{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1\n",
    "Some functions that might be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "def batches_gen(smiles, batchsize, encoder):\n",
    "    '''Create a generator that returns batches of size (batch_size,seq_leng,nchars) from smiles, \n",
    "    where seq_leng is the length of the longest smiles string and nchar is the length of one-hot encoded characters (17)\n",
    "       \n",
    "       Arguments\n",
    "       ---------\n",
    "       smiles: python list(nsmiles,nchar) smiles array shape you want to make batches from\n",
    "       batchsize: Batch size, the number of sequences per batch\n",
    "       encoder: one hot encoder\n",
    "\n",
    "    '''\n",
    "    arr=[torch.tensor(np.array(encoder.transform(np.array(s).reshape(-1,1)).toarray()),dtype=torch.float) for s in smiles] \n",
    "        #size (nsmiles,seq_length(variable),nchars)\n",
    "        \n",
    "    # The features\n",
    "    X = [s[:-1,:] for s in arr]\n",
    "    # The targets, shifted by one\n",
    "    y = [s[1:,:] for s in arr]\n",
    "    # pad sequence so that all smiles are the same length\n",
    "    X = nn.utils.rnn.pad_sequence(X,batch_first=True)\n",
    "    y = nn.utils.rnn.pad_sequence(y,batch_first=True)\n",
    "\n",
    "    \n",
    "    for i in range(len(arr)//batchsize):\n",
    "        yield X[i*batchsize:(i+1)*batchsize],y[i*batchsize:(i+1)*batchsize]\n",
    "        \n",
    "    #drop last batch that is not the same size due to hidden state constraint\n",
    "\n",
    "    \n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a method to generate the next character\n",
    "def predict(net, inputs, h, top_k=None):\n",
    "        ''' Given a onehot encoded character, predict the next character.\n",
    "            Returns the predicted onehot encoded character and the hidden state.\n",
    "        Arguments:\n",
    "            net: the lstm model\n",
    "            inputs: input to the lstm model. shape (batch, time_step/length_of_smiles, input_size) with batchsize of 1\n",
    "            h: hidden state (h,c)\n",
    "            top_k: int. sample from top k possible characters\n",
    "            \n",
    "        '''\n",
    "        # detach hidden state from history\n",
    "        h = tuple([each.data for each in h])\n",
    "        # get the output of the model\n",
    "        out, h = net(inputs, h)\n",
    "        # get the character probabilities\n",
    "        p = out.data\n",
    "\n",
    "        # get top characters\n",
    "        if top_k is None:\n",
    "            top_ch = np.arange(len(net.chars)) #index to choose from\n",
    "        else:\n",
    "            p, top_ch = p.topk(top_k)\n",
    "            top_ch = top_ch.numpy().squeeze()\n",
    "        # select the likely next character with some element of randomness\n",
    "        p = p.numpy().squeeze()\n",
    "        char = np.random.choice(top_ch, p=p/p.sum())\n",
    "        # return the onehot encoded value of the predicted char and the hidden state\n",
    "        output = np.zeros(inputs.detach().numpy().shape)\n",
    "        output[:,:,char] = 1\n",
    "        output = torch.tensor(output,dtype=torch.float)\n",
    "        return output, h\n",
    "\n",
    "# Declaring a method to generate new text\n",
    "def sample(net, encoder, prime=['SOS'], top_k=None):\n",
    "    \"\"\"generate a smiles string starting from prime. I use 'SOS' (start of string) and 'EOS'(end of string). \n",
    "    You may need to change this based on your starting and ending character.\n",
    "\n",
    "    \"\"\"\n",
    "    net.eval() # eval mode\n",
    "    # get initial hidden state with batchsize 1\n",
    "    h = net.init_state(1)\n",
    "    # First off, run through the prime characters\n",
    "    chars=[]\n",
    "    for ch in prime:\n",
    "        ch = encoder.transform(np.array([ch]).reshape(-1, 1)).toarray() #(1,17)\n",
    "        ch = torch.tensor(ch,dtype=torch.float).reshape(1,1,17)\n",
    "        char, h = predict(net, ch, h, top_k=top_k)\n",
    "    chars.append(char)\n",
    "    end  = encoder.transform(np.array(['EOS']).reshape(-1, 1)).toarray()\n",
    "    end = torch.tensor(end,dtype=torch.float).reshape(1,1,17)\n",
    "\n",
    "    # Now pass in the previous character and get a new one\n",
    "    while not torch.all(end.eq(chars[-1])):\n",
    "        char, h = predict(net, chars[-1], h, top_k=top_k)\n",
    "        chars.append(char)\n",
    "    chars =[c.detach().numpy() for c in chars]\n",
    "    chars = np.array(chars).reshape(-1,17)\n",
    "    chars = encoder.inverse_transform(chars).reshape(-1)\n",
    "    return ''.join(chars[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A website to check if your smiles is valid: https://chemwriter.com/smiles/ It'll show you a figure for the valid string!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
